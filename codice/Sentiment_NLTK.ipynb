{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3408,
     "status": "ok",
     "timestamp": 1620938298742,
     "user": {
      "displayName": "Gabriele Strano",
      "photoUrl": "",
      "userId": "12088820102399835684"
     },
     "user_tz": -120
    },
    "id": "kybGYuLy4YnL",
    "outputId": "0bcff64e-dcae-4160-8afd-723569e23cda"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /opt/conda/lib/python3.7/site-packages (3.6.2)\n",
      "Requirement already satisfied: joblib in /opt/conda/lib/python3.7/site-packages (from nltk) (0.13.2)\n",
      "Requirement already satisfied: click in /opt/conda/lib/python3.7/site-packages (from nltk) (7.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from nltk) (4.32.2)\n",
      "Requirement already satisfied: regex in /opt/conda/lib/python3.7/site-packages (from nltk) (2021.4.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 1023,
     "status": "ok",
     "timestamp": 1620938300160,
     "user": {
      "displayName": "Gabriele Strano",
      "photoUrl": "",
      "userId": "12088820102399835684"
     },
     "user_tz": -120
    },
    "id": "K7A6lAqn4ekH"
   },
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "executionInfo": {
     "elapsed": 562,
     "status": "ok",
     "timestamp": 1620938307369,
     "user": {
      "displayName": "Gabriele Strano",
      "photoUrl": "",
      "userId": "12088820102399835684"
     },
     "user_tz": -120
    },
    "id": "-XRCmyw8WXr1"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pymongo import MongoClient\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "client= MongoClient('mongo', 27017, username='admin', password='DataMan2019!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>609909ba97f00aae66f41d39</td>\n",
       "      <td>RT @gaysforkim: TW // bombing, shooting, attac...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>609909ba97f00aae66f41d3a</td>\n",
       "      <td>Our regularly updated interactive databank hel...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>609909ba97f00aae66f41d3b</td>\n",
       "      <td>RT @ozget0rer: Forgiveness is the key to letti...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>609909ba97f00aae66f41d3c</td>\n",
       "      <td>RT @NCTsmtown_DREAM: It’s finally today!! We p...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>609909ba97f00aae66f41d3d</td>\n",
       "      <td>someone brought this back on my tl and i for r...</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  609909ba97f00aae66f41d39   \n",
       "1  609909ba97f00aae66f41d3a   \n",
       "2  609909ba97f00aae66f41d3b   \n",
       "3  609909ba97f00aae66f41d3c   \n",
       "4  609909ba97f00aae66f41d3d   \n",
       "\n",
       "                                                text hashtags  \n",
       "0  RT @gaysforkim: TW // bombing, shooting, attac...       []  \n",
       "1  Our regularly updated interactive databank hel...       []  \n",
       "2  RT @ozget0rer: Forgiveness is the key to letti...       []  \n",
       "3  RT @NCTsmtown_DREAM: It’s finally today!! We p...       []  \n",
       "4  someone brought this back on my tl and i for r...       []  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db = list(client.Progetto_dm.Database_pulito.find())\n",
    "tweets = pd.DataFrame(db)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/jovyan/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download([\"stopwords\",\"vader_lexicon\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La seguente funzione rimuove: le emoticons, la punteggiatura, simboli come # e RT, i collegamenti ipertestuali ed un corpus di parole che NLTK chiama “Stopwords” cioè quelle parole che fungono da congiunzione ma non aggiungono significato alla frase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 556,
     "status": "ok",
     "timestamp": 1620938317344,
     "user": {
      "displayName": "Gabriele Strano",
      "photoUrl": "",
      "userId": "12088820102399835684"
     },
     "user_tz": -120
    },
    "id": "ge-kSN9s6UO3"
   },
   "outputs": [],
   "source": [
    "import string\n",
    "import re\n",
    "\n",
    "from nltk.corpus import stopwords \n",
    "stopwords_english = stopwords.words('english')\n",
    "\n",
    "from nltk.stem import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "\n",
    "# Happy Emoticons\n",
    "emoticons_happy = set([\n",
    "    ':-)', ':)', ';)', ':o)', ':]', ':3', ':c)', ':>', '=]', '8)', '=)', ':}',\n",
    "    ':^)', ':-D', ':D', '8-D', '8D', 'x-D', 'xD', 'X-D', 'XD', '=-D', '=D',\n",
    "    '=-3', '=3', ':-))', \":'-)\", \":')\", ':*', ':^*', '>:P', ':-P', ':P', 'X-P',\n",
    "    'x-p', 'xp', 'XP', ':-p', ':p', '=p', ':-b', ':b', '>:)', '>;)', '>:-)',\n",
    "    '<3'\n",
    "    ])\n",
    "\n",
    "# Sad Emoticons\n",
    "emoticons_sad = set([\n",
    "    ':L', ':-/', '>:/', ':S', '>:[', ':@', ':-(', ':[', ':-||', '=L', ':<',\n",
    "    ':-[', ':-<', '=\\\\', '=/', '>:(', ':(', '>.<', \":'-(\", \":'(\", ':\\\\', ':-c',\n",
    "    ':c', ':{', '>:\\\\', ';('\n",
    "    ])\n",
    "\n",
    "# all emoticons (happy + sad)\n",
    "emoticons = emoticons_happy.union(emoticons_sad)\n",
    "\n",
    "def clean_tweets(tweet):\n",
    "\t# remove stock market tickers like $GE\n",
    "\ttweet = re.sub(r'\\$\\w*', '', tweet)\n",
    "\n",
    "\t# remove old style retweet text \"RT\"\n",
    "\ttweet = re.sub(r'^RT[\\s]+', '', tweet)\n",
    "\n",
    "\t# remove hyperlinks\n",
    "\ttweet = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', tweet)\n",
    "\t\n",
    "\t# remove hashtags\n",
    "\t# only removing the hash # sign from the word\n",
    "\ttweet = re.sub(r'#', '', tweet)\n",
    "\n",
    "\t# tokenize tweets\n",
    "\ttokenizer = TweetTokenizer(preserve_case=False, strip_handles=True, reduce_len=True)\n",
    "\ttweet_tokens = tokenizer.tokenize(tweet)\n",
    "\n",
    "\ttweets_clean = []\t\n",
    "\tfor word in tweet_tokens:\n",
    "\t\tif (word not in stopwords_english and # remove stopwords\n",
    "\t\t\t  word not in emoticons and # remove emoticons\n",
    "\t\t\t    word not in string.punctuation): # remove punctuation\n",
    "\t\t\t#tweets_clean.append(word)\n",
    "\t\t\tstem_word = stemmer.stem(word) # stemming word\n",
    "\t\t\ttweets_clean.append(stem_word)\n",
    "\n",
    "\treturn tweets_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "ZPsKrC36lTem"
   },
   "outputs": [],
   "source": [
    "tweets['puliti'] = tweets['text'].apply(lambda x: clean_tweets(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adesso effettuo la sentiment delle frasi, come media della sentiment delle singole parole che le compongono"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "xQaN2GQ4lTUL"
   },
   "outputs": [],
   "source": [
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "tweets['puliti2'] = tweets['puliti'].str.join(\" \")\n",
    "tweets['score1'] = tweets['puliti2'].apply(lambda x: sia.polarity_scores(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_id</th>\n",
       "      <th>text</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>puliti</th>\n",
       "      <th>puliti2</th>\n",
       "      <th>score1</th>\n",
       "      <th>score2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>609909ba97f00aae66f41d39</td>\n",
       "      <td>RT @gaysforkim: TW // bombing, shooting, attac...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[tw, bomb, shoot, attack, know, what', happen,...</td>\n",
       "      <td>tw bomb shoot attack know what' happen rn pl l...</td>\n",
       "      <td>{'neg': 0.442, 'neu': 0.558, 'pos': 0.0, 'comp...</td>\n",
       "      <td>{'neg': 0.442, 'neu': 0.558, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>609909ba97f00aae66f41d3a</td>\n",
       "      <td>Our regularly updated interactive databank hel...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[regularli, updat, interact, databank, help, s...</td>\n",
       "      <td>regularli updat interact databank help see pla...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>609909ba97f00aae66f41d3b</td>\n",
       "      <td>RT @ozget0rer: Forgiveness is the key to letti...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[forgiv, key, let, go, forgiv, releas, releas]</td>\n",
       "      <td>forgiv key let go forgiv releas releas</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>609909ba97f00aae66f41d3c</td>\n",
       "      <td>RT @NCTsmtown_DREAM: It’s finally today!! We p...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[’, final, today, prepar, lot, comeback, despe...</td>\n",
       "      <td>’ final today prepar lot comeback desper show ...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...</td>\n",
       "      <td>{'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>609909ba97f00aae66f41d3d</td>\n",
       "      <td>someone brought this back on my tl and i for r...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[someon, brought, back, tl, real, broke, tear,...</td>\n",
       "      <td>someon brought back tl real broke tear jisung ...</td>\n",
       "      <td>{'neg': 0.237, 'neu': 0.763, 'pos': 0.0, 'comp...</td>\n",
       "      <td>{'neg': 0.237, 'neu': 0.763, 'pos': 0.0, 'comp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        _id  \\\n",
       "0  609909ba97f00aae66f41d39   \n",
       "1  609909ba97f00aae66f41d3a   \n",
       "2  609909ba97f00aae66f41d3b   \n",
       "3  609909ba97f00aae66f41d3c   \n",
       "4  609909ba97f00aae66f41d3d   \n",
       "\n",
       "                                                text hashtags  \\\n",
       "0  RT @gaysforkim: TW // bombing, shooting, attac...       []   \n",
       "1  Our regularly updated interactive databank hel...       []   \n",
       "2  RT @ozget0rer: Forgiveness is the key to letti...       []   \n",
       "3  RT @NCTsmtown_DREAM: It’s finally today!! We p...       []   \n",
       "4  someone brought this back on my tl and i for r...       []   \n",
       "\n",
       "                                              puliti  \\\n",
       "0  [tw, bomb, shoot, attack, know, what', happen,...   \n",
       "1  [regularli, updat, interact, databank, help, s...   \n",
       "2     [forgiv, key, let, go, forgiv, releas, releas]   \n",
       "3  [’, final, today, prepar, lot, comeback, despe...   \n",
       "4  [someon, brought, back, tl, real, broke, tear,...   \n",
       "\n",
       "                                             puliti2  \\\n",
       "0  tw bomb shoot attack know what' happen rn pl l...   \n",
       "1  regularli updat interact databank help see pla...   \n",
       "2             forgiv key let go forgiv releas releas   \n",
       "3  ’ final today prepar lot comeback desper show ...   \n",
       "4  someon brought back tl real broke tear jisung ...   \n",
       "\n",
       "                                              score1  \\\n",
       "0  {'neg': 0.442, 'neu': 0.558, 'pos': 0.0, 'comp...   \n",
       "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...   \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...   \n",
       "3  {'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...   \n",
       "4  {'neg': 0.237, 'neu': 0.763, 'pos': 0.0, 'comp...   \n",
       "\n",
       "                                              score2  \n",
       "0  {'neg': 0.442, 'neu': 0.558, 'pos': 0.0, 'comp...  \n",
       "1  {'neg': 0.0, 'neu': 0.769, 'pos': 0.231, 'comp...  \n",
       "2  {'neg': 0.0, 'neu': 1.0, 'pos': 0.0, 'compound...  \n",
       "3  {'neg': 0.0, 'neu': 0.783, 'pos': 0.217, 'comp...  \n",
       "4  {'neg': 0.237, 'neu': 0.763, 'pos': 0.0, 'comp...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "tweets['score2'] = tweets['score1']\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dopo esserci documentati al riguardo, abbiamo scelto di non affidarci al valore della voce compound ma di creare una nuova colonna di score che contenesse il valore più alto tra positive e negative o il valore neutral quando nessuno dei due prevaleva sull’altro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0% |                                                                        |\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-587b093e694c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpbar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtweets\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'score1'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     tweets['score2'][i] = np.where((tweets['score1'][i]['pos'] > tweets['score1'][i]['neg']), tweets['score1'][i]['pos'], \n\u001b[0;32m----> 6\u001b[0;31m                                  (np.where((tweets['score1'][i]['neg'] > tweets['score1'][i]['pos']), f\"-{tweets['score1'][i]['neg']}\", 0)))\n\u001b[0m\u001b[1;32m      7\u001b[0m   \u001b[0;31m# do stuff\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m   1241\u001b[0m         \u001b[0msetitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1242\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcacher_needs_updating\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1243\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_update_cacher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1245\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set_with_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_update_cacher\u001b[0;34m(self, clear, verify_is_copy)\u001b[0m\n\u001b[1;32m   3346\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3347\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3348\u001b[0;31m                     \u001b[0mref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_cache_changed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3349\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3350\u001b[0m                     \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_maybe_cache_changed\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   3303\u001b[0m         \"\"\"The object has called back to us saying maybe it has changed.\n\u001b[1;32m   3304\u001b[0m         \"\"\"\n\u001b[0;32m-> 3305\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3307\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/managers.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, item, value)\u001b[0m\n\u001b[1;32m   1088\u001b[0m             \u001b[0mblk_locs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblklocs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindexer\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1089\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_store\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1090\u001b[0;31m                 \u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_getitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_locs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1091\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1092\u001b[0m                 \u001b[0munfit_mgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmgr_locs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblk_locs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/pandas/core/internals/blocks.py\u001b[0m in \u001b[0;36mset\u001b[0;34m(self, locs, values)\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m         \"\"\"\n\u001b[0;32m--> 380\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlocs\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdelete\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from progressbar import ProgressBar\n",
    "pbar = ProgressBar()\n",
    "\n",
    "for i in pbar(range(len(tweets['score1']))):\n",
    "    tweets['score2'][i] = np.where((tweets['score1'][i]['pos'] > tweets['score1'][i]['neg']), tweets['score1'][i]['pos'], \n",
    "                                 (np.where((tweets['score1'][i]['neg'] > tweets['score1'][i]['pos']), f\"-{tweets['score1'][i]['neg']}\", 0)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rimuoviamo le colonne che ci sono servite solo per le lavorazioni."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 577,
     "status": "ok",
     "timestamp": 1620938393281,
     "user": {
      "displayName": "Gabriele Strano",
      "photoUrl": "",
      "userId": "12088820102399835684"
     },
     "user_tz": -120
    },
    "id": "LqMhT2j8vMf7"
   },
   "outputs": [],
   "source": [
    "tweets.drop([\"puliti\", \"puliti2\"], axis=1, inplace= True)\n",
    "tweets.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trasformiano la colonna score2 in float. Prima era un array Numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets['score2'] = tweets['score2'].astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_d = tweets.to_dict(orient='records')\n",
    "tweets_d.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.Progetto_dm.Database_pulito_sentiment.insert_many(tweets_d)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOUt8LacYwP49yicULj6MNv",
   "collapsed_sections": [],
   "name": "FINALE lavori in corso NLTK.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
