{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fase di import delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importazione dei due db <br>\n",
    "**Netflix:** database riferito a tutte le serie Netflix aggiornato al 2019 <br>\n",
    "**IMDB:** database riferito ai rating del sito IMDB aggiornato al 2020 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix=pd.read_csv('netflix_titles.csv')\n",
    "IMDB=pd.read_csv('series_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "IMDB.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTEGRAZIONE DEI DUE DATABASE** <br>\n",
    "Merge dei due database, in formato csv, prendendo in considerazione solo le serie tv.\n",
    "\n",
    "Prima dell'integrazione, abbiamo effettuato una normalizzazione sulle colonne dei titoli delle serie tv.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDB['Series_Title_norm'] = IMDB['Series_Title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "netflix['title_norm'] = netflix['title'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unione=pd.merge(netflix, IMDB, left_on = 'title_norm', right_on = 'Series_Title_norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "unione.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unione=unione[unione['type']=='TV Show']\n",
    "#sono solamente 2 i film, solo serie tv in comune sono 392"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unione.drop(['Series_Title', 'Poster_Link','listed_in','Star1', 'Star2', 'Star3', 'Star4','release_year','Runtime_of_Series','date_added','description', 'Overview' ], axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unione.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**INTEGRAZIONE CON JSON**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fase di importazione delle librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lettura file json contenente i tweet\n",
    "tweet=pd.read_json(\"finale.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rimozione carattere 'oid' aggiunto da mongo \n",
    "tweet[\"_id\"] = tweet[\"_id\"].map(lambda x: x['$oid'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FUNZIONE PER LA PULIZIA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importazione di emoji: un package in cui sono contenute le emoji\n",
    "import string\n",
    "import re\n",
    "import emoji\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(tweet):\n",
    "    tweet = re.sub(\"@[A-Za-z0-9]+\",\"\",tweet) #rimuove @\n",
    "    tweet = re.sub(\"~[A-Za-z0-9]+\",\"\",tweet) #rimuove @\n",
    "    tweet = re.sub(r\"(?:\\@|http?\\://|https?\\://|www)\\S+\", \"\", tweet) #Rimuove il link\n",
    "    tweet = \" \".join(tweet.split())\n",
    "    tweet = ''.join(c for c in tweet if c not in emoji.UNICODE_EMOJI) #Rimuove le emojis\n",
    "    tweet = tweet.replace(\"#\", \"\").replace(\"_\", \" \") #Rimuove il simbolodell'hashtag ma tiene il testo dell'hashtag\n",
    "    #per i simboli che noon vengono presi dalle istruzioni precedenti \n",
    "    emoj = re.compile(\"[\" \n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"  #emojii della forbice \n",
    "        u\"\\U00002702-\\U000027B0\"  #\n",
    "        u\"\\U000024C2-\\U0001F251\"  #accept\n",
    "        u\"\\U0001f926-\\U0001f937\"  #facepalm/SHRUG\n",
    "        u\"\\U00010000-\\U0010ffff\"#stop\n",
    "        \"U+007E\" #tilde \n",
    "        u\"\\u2640-\\u2642\" #simbolo male\n",
    "        u\"\\u2600-\\u2B55\"#ancora-cerchio nero \n",
    "        u\"\\u200d\" #ZERO WIDTH JOINER'\n",
    "        u\"\\u23cf\" #simbolo eject\n",
    "        u\"\\u23e9\" #simbolo avanti \n",
    "        u\"\\u231a\" #orologio\n",
    "        \"U+20AC\" #a cappuccio\n",
    "        \"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\" #baffi\n",
    "                      \"]+\", re.UNICODE)\n",
    "    return re.sub(emoj, '', tweet)\n",
    "    return tweet\n",
    "\n",
    "#link delle emoji \n",
    "#http://unicode.org/reports/tr51/tr51-12.html#Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applico la funzione cleaner alla colonna text e salvo tutto in una colonna text_cleaned\n",
    "tweet['text_cleaned'] = tweet['text'].map(lambda x: cleaner(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['text_cleaned']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#applico la funzione cleaner_punctuation alla colonna text_cleaned e salvo tutto in una colonna text_cleaned_punctuation\n",
    "def cleaner_punctuation(tweet):\n",
    "    exclude = set(string.punctuation)\n",
    "    tweet = ''.join(ch for ch in tweet if ch not in exclude)\n",
    "    return tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['text_cleaned_punctuation'] = tweet['text_cleaned'].map(lambda x: cleaner_punctuation(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet['text_cleaned_punctuation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#ricerca dei titoli delle serie tv presenti nel testo del tweet con creazione della colonna title per facilitare l'integrazione finale\n",
    "i=0\n",
    "tweet['title']=''\n",
    "for testo in tweet['text_cleaned_punctuation']:\n",
    "    titolo_match=''\n",
    "    count_match=0\n",
    "    for titolo in unione['title']:\n",
    "        if titolo in testo:\n",
    "            titolo_match=titolo\n",
    "            count_match+=1\n",
    "    \n",
    "    if (count_match>1 or count_match==0):\n",
    "        tweet.drop(i, inplace=True)\n",
    "    else: \n",
    "        tweet['title'][i]=titolo_match\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#integrazione finale tra dataset twitter e unione precedente di IMDB e Netflix\n",
    "finale=pd.merge(unione, tweet, left_on='title', right_on='title')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "finale.drop(['Unnamed: 0'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=finale.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import groupby\n",
    "from operator import itemgetter\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jupyter notebook --NotebookApp.iopub_data_rate_limit=1.0e10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregazione di tutti i tweet riferiti ad una specifica serie tv\n",
    "move = '_id','text','hashtags','score1','score2','text_cleaned__punctuation'\n",
    "\n",
    "key = itemgetter('show_id')\n",
    "data.sort(key=key)\n",
    "\n",
    "result = []\n",
    "for show_id,group in groupby(data,key=key):\n",
    "    for i,item in enumerate(group):\n",
    "        if i == 0: \n",
    "            current = item \n",
    "            result.append(current)\n",
    "            current['tweet'] = []\n",
    "\n",
    "        current_tweet = {} \n",
    "        current['tweet'].append(current_tweet)\n",
    "        for movekey in move:\n",
    "            current_tweet[movekey] = item[movekey]\n",
    "            if i == 0: \n",
    "                del current[movekey]\n",
    "\n",
    "print(json.dumps(result,indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('integrazione.json', 'w') as f:\n",
    "    f.write(result + \"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
